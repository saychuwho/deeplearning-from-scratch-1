{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6장 학습 관련 기술들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 매개변수 갱신\n",
    "\n",
    "<img src=\"./img/6_1_slide.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import load_mnist\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD : $\\eta$는 학습률(learning rate)\n",
    "\n",
    "$\\mathbf{W} \\leftarrow \\mathbf{W}-\\eta{\\partial{L}\\over{\\partial\\mathbf{W}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.2 확률적 경사 하강법(SGD)\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum : $\\alpha$는 0.9 정도로 설정함 보통\n",
    "\n",
    "$\\mathbf{v} \\leftarrow \\alpha\\mathbf{v}-\\eta{\\partial{L}\\over{\\partial\\mathbf{W}}}$\n",
    "\n",
    "$\\mathbf{W} \\leftarrow \\mathbf{W}+\\mathbf{v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.4 모멘텀\n",
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad: 개별 매개변수에 맞는 학습률을 적용하는 방법\n",
    "\n",
    "$\\mathbf{h}$에 기존 기울기 값을 계속 제곱해서 더해나가고, 학습률을 ${1\\over{\\sqrt{\\mathbf{h}}}}$만큼 계속 조정해나간다. 이 의미는 매개변수 중 갱신이 많이 된 매개변수는 학습률이 낮아진다는 뜻이다. \n",
    "\n",
    "$\\mathbf{h} \\leftarrow \\mathbf{h} + {\\partial{L}\\over{\\partial\\mathbf{W}}} \\odot {\\partial{L}\\over{\\partial\\mathbf{W}}}$\n",
    "\n",
    "$\\mathbf{W} \\leftarrow \\mathbf{W}-\\eta{1\\over{\\sqrt{\\mathbf{h}}}}{\\partial{L}\\over{\\partial\\mathbf{W}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.5 AdaGrad\n",
    "\n",
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam : AdaGrad와 Momentum의 짬뽕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" code from https://github.com/WegraLee/deep-learning-from-scratch/blob/master/common/optimizer.py \"\"\"\n",
    "\n",
    "class Adam:\n",
    "\n",
    "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        \n",
    "        for key in params.keys():\n",
    "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
    "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])  # 일종의 모멘텀 효과를 주는거 같다.\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])  # 일종의 AdaGrad 효과를 주는거 같다.\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
    "            \n",
    "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n",
    "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n",
    "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 가중치의 초깃값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid나 tanh 같은 활성화 함수의 경우에는 초기값으로 \"Xavier 초기값\"을 이용하는 것이 유리하다. \"Xavier 초깃값\"은 랜덤한 초깃값을 뽑을 때, 앞 계층의 노드가 $n$일때, 표준편차가 $\\sqrt{1\\over{n}}$인 정규분포를 사용한다.\n",
    "\n",
    "ReLU를 활성화 함수로 이용할 때는 \"He 초깃값\"을 이용하는 것이 유리하다. \"He 초깃값\"은 랜덤한 초깃값을 뽑을 때, 앞 계층의 노드가 $n$일때, 표준편차가 $\\sqrt{2\\over{n}}$인 정규분포를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 배치 정규화\n",
    "\n",
    "각 층이 활성화를 적당히 퍼뜨릴 수 있도록 강제하는 것이 배치 정규화가 나오게 된 아이디어이다.\n",
    "\n",
    "구체적으로는 미니배치를 단위로 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 바른 학습을 위해\n",
    "\n",
    "오버피팅을 피하기 위한 다양한 방법들이 제안되었다.\n",
    "\n",
    "가중치 감소 : L1 loss, L2 loss등이 그 방법이다. 손실 함수에 가중치를 감소시키는 L1 loss, L2 loss 항을 넣어서 가중치를 전반적으로 감소시키는 방법이다.\n",
    "\n",
    "드롭아웃 : 뉴런을 임의로 삭제하면서 학습하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4.3 드롭아웃\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            # x와 형상이 같은 배열을 무작위로 생성하고, 그 값이 dropout_ratio보다 큰 원소만 True로 설정\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            # 여기서 순전파시 dropout에서 제외된 원소들로만 순전파가 이루어짐.\n",
    "            return x * self.mask \n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 적절한 하이퍼파라미터 값 찾기\n",
    "\n",
    "하이퍼파라미터를 시험할 때는 test data를 사용하지 말고, validation data라고 하는 새로운 데이터셋을 사용해야 한다. MNIST의 경우에는 사용자가 직접 분리해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5.1 검증 데이터 분리\n",
    "\n",
    "from mnist import load_mnist\n",
    "from util import shuffle_dataset\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist()\n",
    "\n",
    "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
    "validation_rate = 0.20\n",
    "validation_num = int(x_train.shape[0] * validation_rate)\n",
    "\n",
    "x_val = x_train[:validation_num]\n",
    "t_val = t_train[:validation_num]\n",
    "x_train = x_train[validation_num:]\n",
    "t_train = t_train[validation_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 값을 최적화하는 과정은 다음과 같다.\n",
    "\n",
    "- 0단계 : 하이퍼파라미터 값의 범위를 설정한다. 로그스케일로 범위를 보통 정한다.\n",
    "- 1단계 : 설정된 범위에서 하이퍼파라미터의 값을 무작위로 추출합니다.\n",
    "- 2단계 : 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가한다.(에폭은 작게 설정)\n",
    "- 3단계 : 1단계와 2단계를 특정 횟수(100회 등) 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다.\n",
    "\n",
    "좀 감에 의존하는 것처럼 보인다. 보다 수학적으로 이를 최적화하는 방법으로는 베이즈 최적화가 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
